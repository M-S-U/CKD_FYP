{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/MedVita/medgemma-27b-lora-swift\n",
        "\n",
        "âš ï¸ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/MedVita/medgemma-27b-lora-swift)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) ðŸ™"
      ],
      "metadata": {
        "id": "TV4pp_2STmrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"google/medgemma-27b-it\")\n",
        "model = PeftModel.from_pretrained(base_model, \"MedVita/medgemma-27b-lora-swift\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "Az47gWcuTmrn",
        "outputId": "85b19d53-f786-45e0-b8f8-96015ec9be04"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/medgemma-27b-it.\n401 Client Error. (Request ID: Root=1-692efff8-25d6a8312a43ff2975eea23b;25f044ca-8178-4482-b9ac-d0e2f29d9305)\n\nCannot access gated repo for url https://huggingface.co/google/medgemma-27b-it/resolve/main/config.json.\nAccess to model google/medgemma-27b-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/medgemma-27b-it/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-692efff8-25d6a8312a43ff2975eea23b;25f044ca-8178-4482-b9ac-d0e2f29d9305)\n\nCannot access gated repo for url https://huggingface.co/google/medgemma-27b-it/resolve/main/config.json.\nAccess to model google/medgemma-27b-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2149325970.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/medgemma-27b-it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MedVita/medgemma-27b-lora-swift\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    550\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/medgemma-27b-it.\n401 Client Error. (Request ID: Root=1-692efff8-25d6a8312a43ff2975eea23b;25f044ca-8178-4482-b9ac-d0e2f29d9305)\n\nCannot access gated repo for url https://huggingface.co/google/medgemma-27b-it/resolve/main/config.json.\nAccess to model google/medgemma-27b-it is restricted. You must have access to it and be authenticated to access it. Please log in."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_LjQYtpbUI57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sairajkadam/MedViT-small\"\n",
        "\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels=4)\n"
      ],
      "metadata": {
        "id": "-slBYIiaT375"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1IqwnM9T34Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkcDXKMMT314"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kfYY23ncbvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhkHN4JXcbr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZCszqfvcbpe",
        "outputId": "1766794d-b6a7-4292-c5d5-d014ea572449"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  2 15:04:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_9TqMAVcbm7",
        "outputId": "3cdf79c9-8985-4083-90f1-45f0168da423"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MedViT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/MedViT"
      ],
      "metadata": {
        "id": "imJ_gNOGcbkR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "W11xa4AZc7IT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCGR3Pmzc7E0",
        "outputId": "a55ebdf2-7eb6-41af-dd56-dd1f508662d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/MedViT')\n",
        "\n",
        "import importlib.util\n",
        "\n",
        "medvit_path = '/content/MedViT/MedViT.py'\n",
        "spec = importlib.util.spec_from_file_location(\"medvit_model_module\", medvit_path)\n",
        "medvit_model_module = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"medvit_model_module\"] = medvit_model_module\n",
        "spec.loader.exec_module(medvit_model_module)\n",
        "\n",
        "tiny = medvit_model_module.MedViT_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyftvFPGc7Cf",
        "outputId": "c6f46534-6ec9-4f60-dd5d-6675e55172b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -F /content/MedViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpq1PsOWc6_5",
        "outputId": "53870959-c74a-493a-ae74-d1fe1fa7911b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab_MedViT.ipynb  images/\t\tMedViT.py     requirements.txt\n",
            "CustomDataset/\t    Instructions.ipynb\t__pycache__/  utils.py\n",
            "CustomDataset.md    LICENSE\t\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/MedViT/MedViT.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MkOVknuc69d",
        "outputId": "0f88f0d6-cb7c-4c31-efb0-5d87af2d8747"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"\n",
            "Author: Omid Nejati\n",
            "Email: omid_nejaty@alumni.iust.ac.ir\n",
            "\n",
            "MedViT: A Robust Vision Transformer for Generalized Medical Image Classification.\n",
            "\"\"\"\n",
            "from functools import partial\n",
            "import math\n",
            "import torch\n",
            "import torch.utils.checkpoint as checkpoint\n",
            "from einops import rearrange\n",
            "from timm.models.layers import DropPath, trunc_normal_\n",
            "from timm.models.registry import register_model\n",
            "from torch import nn\n",
            "from utils import merge_pre_bn\n",
            "\n",
            "NORM_EPS = 1e-5\n",
            "\n",
            "\n",
            "class ConvBNReLU(nn.Module):\n",
            "    def __init__(\n",
            "            self,\n",
            "            in_channels,\n",
            "            out_channels,\n",
            "            kernel_size,\n",
            "            stride,\n",
            "            groups=1):\n",
            "        super(ConvBNReLU, self).__init__()\n",
            "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride,\n",
            "                              padding=1, groups=groups, bias=False)\n",
            "        self.norm = nn.BatchNorm2d(out_channels, eps=NORM_EPS)\n",
            "        self.act = nn.ReLU(inplace=True)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.conv(x)\n",
            "        x = self.norm(x)\n",
            "        x = self.act(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "def _make_divisible(v, divisor, min_value=None):\n",
            "    if min_value is None:\n",
            "        min_value = divisor\n",
            "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
            "    # Make sure that round down does not go down by more than 10%.\n",
            "    if new_v < 0.9 * v:\n",
            "        new_v += divisor\n",
            "    return new_v\n",
            "\n",
            "\n",
            "class PatchEmbed(nn.Module):\n",
            "    def __init__(self,\n",
            "                 in_channels,\n",
            "                 out_channels,\n",
            "                 stride=1):\n",
            "        super(PatchEmbed, self).__init__()\n",
            "        norm_layer = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
            "        if stride == 2:\n",
            "            self.avgpool = nn.AvgPool2d((2, 2), stride=2, ceil_mode=True, count_include_pad=False)\n",
            "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
            "            self.norm = norm_layer(out_channels)\n",
            "        elif in_channels != out_channels:\n",
            "            self.avgpool = nn.Identity()\n",
            "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
            "            self.norm = norm_layer(out_channels)\n",
            "        else:\n",
            "            self.avgpool = nn.Identity()\n",
            "            self.conv = nn.Identity()\n",
            "            self.norm = nn.Identity()\n",
            "\n",
            "    def forward(self, x):\n",
            "        return self.norm(self.conv(self.avgpool(x)))\n",
            "\n",
            "\n",
            "class MHCA(nn.Module):\n",
            "    \"\"\"\n",
            "    Multi-Head Convolutional Attention\n",
            "    \"\"\"\n",
            "    def __init__(self, out_channels, head_dim):\n",
            "        super(MHCA, self).__init__()\n",
            "        norm_layer = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
            "        self.group_conv3x3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
            "                                       padding=1, groups=out_channels // head_dim, bias=False)\n",
            "        self.norm = norm_layer(out_channels)\n",
            "        self.act = nn.ReLU(inplace=True)\n",
            "        self.projection = nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False)\n",
            "\n",
            "    def forward(self, x):\n",
            "        out = self.group_conv3x3(x)\n",
            "        out = self.norm(out)\n",
            "        out = self.act(out)\n",
            "        out = self.projection(out)\n",
            "        return out\n",
            "\n",
            "class h_sigmoid(nn.Module):\n",
            "    def __init__(self, inplace=True):\n",
            "        super(h_sigmoid, self).__init__()\n",
            "        self.relu = nn.ReLU6(inplace=inplace)\n",
            "\n",
            "    def forward(self, x):\n",
            "        return self.relu(x + 3) / 6\n",
            "\n",
            "\n",
            "class h_swish(nn.Module):\n",
            "    def __init__(self, inplace=True):\n",
            "        super(h_swish, self).__init__()\n",
            "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
            "\n",
            "    def forward(self, x):\n",
            "        return x * self.sigmoid(x)\n",
            "\n",
            "\n",
            "class ECALayer(nn.Module):\n",
            "    def __init__(self, channel, gamma=2, b=1, sigmoid=True):\n",
            "        super(ECALayer, self).__init__()\n",
            "        t = int(abs((math.log(channel, 2) + b) / gamma))\n",
            "        k = t if t % 2 else t + 1\n",
            "\n",
            "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
            "        self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=k // 2, bias=False)\n",
            "        if sigmoid:\n",
            "            self.sigmoid = nn.Sigmoid()\n",
            "        else:\n",
            "            self.sigmoid = h_sigmoid()\n",
            "\n",
            "    def forward(self, x):\n",
            "        y = self.avg_pool(x)\n",
            "        y = self.conv(y.squeeze(-1).transpose(-1, -2))\n",
            "        y = y.transpose(-1, -2).unsqueeze(-1)\n",
            "        y = self.sigmoid(y)\n",
            "        return x * y.expand_as(x)\n",
            "\n",
            "\n",
            "class SELayer(nn.Module):\n",
            "    def __init__(self, channel, reduction=4):\n",
            "        super(SELayer, self).__init__()\n",
            "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
            "        self.fc = nn.Sequential(\n",
            "                nn.Linear(channel, channel // reduction),\n",
            "                nn.ReLU(inplace=True),\n",
            "                nn.Linear(channel // reduction, channel),\n",
            "                h_sigmoid()\n",
            "        )\n",
            "\n",
            "    def forward(self, x):\n",
            "        b, c, _, _ = x.size()\n",
            "        y = self.avg_pool(x).view(b, c)\n",
            "        y = self.fc(y).view(b, c, 1, 1)\n",
            "        return x * y\n",
            "\n",
            "class LocalityFeedForward(nn.Module):\n",
            "    def __init__(self, in_dim, out_dim, stride, expand_ratio=4., act='hs+se', reduction=4,\n",
            "                 wo_dp_conv=False, dp_first=False):\n",
            "        \"\"\"\n",
            "        :param in_dim: the input dimension\n",
            "        :param out_dim: the output dimension. The input and output dimension should be the same.\n",
            "        :param stride: stride of the depth-wise convolution.\n",
            "        :param expand_ratio: expansion ratio of the hidden dimension.\n",
            "        :param act: the activation function.\n",
            "                    relu: ReLU\n",
            "                    hs: h_swish\n",
            "                    hs+se: h_swish and SE module\n",
            "                    hs+eca: h_swish and ECA module\n",
            "                    hs+ecah: h_swish and ECA module. Compared with eca, h_sigmoid is used.\n",
            "        :param reduction: reduction rate in SE module.\n",
            "        :param wo_dp_conv: without depth-wise convolution.\n",
            "        :param dp_first: place depth-wise convolution as the first layer.\n",
            "        \"\"\"\n",
            "        super(LocalityFeedForward, self).__init__()\n",
            "        hidden_dim = int(in_dim * expand_ratio)\n",
            "        kernel_size = 3\n",
            "\n",
            "        layers = []\n",
            "        # the first linear layer is replaced by 1x1 convolution.\n",
            "        layers.extend([\n",
            "            nn.Conv2d(in_dim, hidden_dim, 1, 1, 0, bias=False),\n",
            "            nn.BatchNorm2d(hidden_dim),\n",
            "            h_swish() if act.find('hs') >= 0 else nn.ReLU6(inplace=True)])\n",
            "\n",
            "        # the depth-wise convolution between the two linear layers\n",
            "        if not wo_dp_conv:\n",
            "            dp = [\n",
            "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, kernel_size // 2, groups=hidden_dim, bias=False),\n",
            "                nn.BatchNorm2d(hidden_dim),\n",
            "                h_swish() if act.find('hs') >= 0 else nn.ReLU6(inplace=True)\n",
            "            ]\n",
            "            if dp_first:\n",
            "                layers = dp + layers\n",
            "            else:\n",
            "                layers.extend(dp)\n",
            "\n",
            "        if act.find('+') >= 0:\n",
            "            attn = act.split('+')[1]\n",
            "            if attn == 'se':\n",
            "                layers.append(SELayer(hidden_dim, reduction=reduction))\n",
            "            elif attn.find('eca') >= 0:\n",
            "                layers.append(ECALayer(hidden_dim, sigmoid=attn == 'eca'))\n",
            "            else:\n",
            "                raise NotImplementedError('Activation type {} is not implemented'.format(act))\n",
            "\n",
            "        # the second linear layer is replaced by 1x1 convolution.\n",
            "        layers.extend([\n",
            "            nn.Conv2d(hidden_dim, out_dim, 1, 1, 0, bias=False),\n",
            "            nn.BatchNorm2d(out_dim)\n",
            "        ])\n",
            "        self.conv = nn.Sequential(*layers)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = x + self.conv(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "class Mlp(nn.Module):\n",
            "    def __init__(self, in_features, out_features=None, mlp_ratio=None, drop=0., bias=True):\n",
            "        super().__init__()\n",
            "        out_features = out_features or in_features\n",
            "        hidden_dim = _make_divisible(in_features * mlp_ratio, 32)\n",
            "        self.conv1 = nn.Conv2d(in_features, hidden_dim, kernel_size=1, bias=bias)\n",
            "        self.act = nn.ReLU(inplace=True)\n",
            "        self.conv2 = nn.Conv2d(hidden_dim, out_features, kernel_size=1, bias=bias)\n",
            "        self.drop = nn.Dropout(drop)\n",
            "\n",
            "    def merge_bn(self, pre_norm):\n",
            "        merge_pre_bn(self.conv1, pre_norm)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.conv1(x)\n",
            "        x = self.act(x)\n",
            "        x = self.drop(x)\n",
            "        x = self.conv2(x)\n",
            "        x = self.drop(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "class ECB(nn.Module):\n",
            "    \"\"\"\n",
            "    Efficient Convolution Block\n",
            "    \"\"\"\n",
            "    def __init__(self, in_channels, out_channels, stride=1, path_dropout=0,\n",
            "                 drop=0, head_dim=32, mlp_ratio=3):\n",
            "        super(ECB, self).__init__()\n",
            "        self.in_channels = in_channels\n",
            "        self.out_channels = out_channels\n",
            "        norm_layer = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
            "        assert out_channels % head_dim == 0\n",
            "\n",
            "        self.patch_embed = PatchEmbed(in_channels, out_channels, stride)\n",
            "        self.mhca = MHCA(out_channels, head_dim)\n",
            "        self.attention_path_dropout = DropPath(path_dropout)\n",
            "\n",
            "        self.conv = LocalityFeedForward(out_channels, out_channels, 1, mlp_ratio, reduction=out_channels)\n",
            "\n",
            "        self.norm = norm_layer(out_channels)\n",
            "        #self.mlp = Mlp(out_channels, mlp_ratio=mlp_ratio, drop=drop, bias=True)\n",
            "        #self.mlp_path_dropout = DropPath(path_dropout)\n",
            "        self.is_bn_merged = False\n",
            "\n",
            "    def merge_bn(self):\n",
            "        if not self.is_bn_merged:\n",
            "            self.mlp.merge_bn(self.norm)\n",
            "            self.is_bn_merged = True\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.patch_embed(x)\n",
            "        x = x + self.attention_path_dropout(self.mhca(x))\n",
            "        if not torch.onnx.is_in_onnx_export() and not self.is_bn_merged:\n",
            "            out = self.norm(x)\n",
            "        else:\n",
            "            out = x\n",
            "        #x = x + self.mlp_path_dropout(self.mlp(out))\n",
            "        x = x + self.conv(out) # (B, dim, 14, 14)\n",
            "        return x\n",
            "\n",
            "\n",
            "class E_MHSA(nn.Module):\n",
            "    \"\"\"\n",
            "    Efficient Multi-Head Self Attention\n",
            "    \"\"\"\n",
            "    def __init__(self, dim, out_dim=None, head_dim=32, qkv_bias=True, qk_scale=None,\n",
            "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
            "        super().__init__()\n",
            "        self.dim = dim\n",
            "        self.out_dim = out_dim if out_dim is not None else dim\n",
            "        self.num_heads = self.dim // head_dim\n",
            "        self.scale = qk_scale or head_dim ** -0.5\n",
            "        self.q = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
            "        self.k = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
            "        self.v = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
            "        self.proj = nn.Linear(self.dim, self.out_dim)\n",
            "        self.attn_drop = nn.Dropout(attn_drop)\n",
            "        self.proj_drop = nn.Dropout(proj_drop)\n",
            "\n",
            "        self.sr_ratio = sr_ratio\n",
            "        self.N_ratio = sr_ratio ** 2\n",
            "        if sr_ratio > 1:\n",
            "            self.sr = nn.AvgPool1d(kernel_size=self.N_ratio, stride=self.N_ratio)\n",
            "            self.norm = nn.BatchNorm1d(dim, eps=NORM_EPS)\n",
            "        self.is_bn_merged = False\n",
            "\n",
            "    def merge_bn(self, pre_bn):\n",
            "        merge_pre_bn(self.q, pre_bn)\n",
            "        if self.sr_ratio > 1:\n",
            "            merge_pre_bn(self.k, pre_bn, self.norm)\n",
            "            merge_pre_bn(self.v, pre_bn, self.norm)\n",
            "        else:\n",
            "            merge_pre_bn(self.k, pre_bn)\n",
            "            merge_pre_bn(self.v, pre_bn)\n",
            "        self.is_bn_merged = True\n",
            "\n",
            "    def forward(self, x):\n",
            "        B, N, C = x.shape\n",
            "        q = self.q(x)\n",
            "        q = q.reshape(B, N, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
            "\n",
            "        if self.sr_ratio > 1:\n",
            "            x_ = x.transpose(1, 2)\n",
            "            x_ = self.sr(x_)\n",
            "            if not torch.onnx.is_in_onnx_export() and not self.is_bn_merged:\n",
            "                x_ = self.norm(x_)\n",
            "            x_ = x_.transpose(1, 2)\n",
            "            k = self.k(x_)\n",
            "            k = k.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
            "            v = self.v(x_)\n",
            "            v = v.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
            "        else:\n",
            "            k = self.k(x)\n",
            "            k = k.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
            "            v = self.v(x)\n",
            "            v = v.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
            "        attn = (q @ k) * self.scale\n",
            "\n",
            "        attn = attn.softmax(dim=-1)\n",
            "        attn = self.attn_drop(attn)\n",
            "\n",
            "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
            "        x = self.proj(x)\n",
            "        x = self.proj_drop(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "class LTB(nn.Module):\n",
            "    \"\"\"\n",
            "    Local Transformer Block\n",
            "    \"\"\"\n",
            "    def __init__(\n",
            "            self, in_channels, out_channels, path_dropout, stride=1, sr_ratio=1,\n",
            "            mlp_ratio=2, head_dim=32, mix_block_ratio=0.75, attn_drop=0, drop=0,\n",
            "    ):\n",
            "        super(LTB, self).__init__()\n",
            "        self.in_channels = in_channels\n",
            "        self.out_channels = out_channels\n",
            "        self.mix_block_ratio = mix_block_ratio\n",
            "        norm_func = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
            "\n",
            "        self.mhsa_out_channels = _make_divisible(int(out_channels * mix_block_ratio), 32)\n",
            "        self.mhca_out_channels = out_channels - self.mhsa_out_channels\n",
            "\n",
            "        self.patch_embed = PatchEmbed(in_channels, self.mhsa_out_channels, stride)\n",
            "        self.norm1 = norm_func(self.mhsa_out_channels)\n",
            "        self.e_mhsa = E_MHSA(self.mhsa_out_channels, head_dim=head_dim, sr_ratio=sr_ratio,\n",
            "                             attn_drop=attn_drop, proj_drop=drop)\n",
            "        self.mhsa_path_dropout = DropPath(path_dropout * mix_block_ratio)\n",
            "\n",
            "        self.projection = PatchEmbed(self.mhsa_out_channels, self.mhca_out_channels, stride=1)\n",
            "        self.mhca = MHCA(self.mhca_out_channels, head_dim=head_dim)\n",
            "        self.mhca_path_dropout = DropPath(path_dropout * (1 - mix_block_ratio))\n",
            "\n",
            "        self.norm2 = norm_func(out_channels)\n",
            "        self.conv = LocalityFeedForward(out_channels, out_channels, 1, mlp_ratio, reduction=out_channels)\n",
            "\n",
            "        #self.mlp = Mlp(out_channels, mlp_ratio=mlp_ratio, drop=drop)\n",
            "        #self.mlp_path_dropout = DropPath(path_dropout)\n",
            "\n",
            "        self.is_bn_merged = False\n",
            "\n",
            "    def merge_bn(self):\n",
            "        if not self.is_bn_merged:\n",
            "            self.e_mhsa.merge_bn(self.norm1)\n",
            "            self.mlp.merge_bn(self.norm2)\n",
            "            self.is_bn_merged = True\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.patch_embed(x)\n",
            "        B, C, H, W = x.shape\n",
            "        if not torch.onnx.is_in_onnx_export() and not self.is_bn_merged:\n",
            "            out = self.norm1(x)\n",
            "        else:\n",
            "            out = x\n",
            "        out = rearrange(out, \"b c h w -> b (h w) c\")  # b n c\n",
            "        out = self.mhsa_path_dropout(self.e_mhsa(out))\n",
            "        x = x + rearrange(out, \"b (h w) c -> b c h w\", h=H)\n",
            "\n",
            "        out = self.projection(x)\n",
            "        out = out + self.mhca_path_dropout(self.mhca(out))\n",
            "        x = torch.cat([x, out], dim=1)\n",
            "\n",
            "        if not torch.onnx.is_in_onnx_export() and not self.is_bn_merged:\n",
            "            out = self.norm2(x)\n",
            "        else:\n",
            "            out = x\n",
            "        x = x + self.conv(out)\n",
            "        #x = x + self.mlp_path_dropout(self.mlp(out))\n",
            "        return x\n",
            "\n",
            "\n",
            "class MedViT(nn.Module):\n",
            "    def __init__(self, stem_chs, depths, path_dropout, attn_drop=0, drop=0, num_classes=1000,\n",
            "                 strides=[1, 2, 2, 2], sr_ratios=[8, 4, 2, 1], head_dim=32, mix_block_ratio=0.75,\n",
            "                 use_checkpoint=False):\n",
            "        super(MedViT, self).__init__()\n",
            "        self.use_checkpoint = use_checkpoint\n",
            "\n",
            "        self.stage_out_channels = [[96] * (depths[0]),\n",
            "                                   [192] * (depths[1] - 1) + [256],\n",
            "                                   [384, 384, 384, 384, 512] * (depths[2] // 5),\n",
            "                                   [768] * (depths[3] - 1) + [1024]]\n",
            "\n",
            "        # Next Hybrid Strategy\n",
            "        self.stage_block_types = [[ECB] * depths[0],\n",
            "                                  [ECB] * (depths[1] - 1) + [LTB],\n",
            "                                  [ECB, ECB, ECB, ECB, LTB] * (depths[2] // 5),\n",
            "                                  [ECB] * (depths[3] - 1) + [LTB]]\n",
            "\n",
            "        self.stem = nn.Sequential(\n",
            "            ConvBNReLU(3, stem_chs[0], kernel_size=3, stride=2),\n",
            "            ConvBNReLU(stem_chs[0], stem_chs[1], kernel_size=3, stride=1),\n",
            "            ConvBNReLU(stem_chs[1], stem_chs[2], kernel_size=3, stride=1),\n",
            "            ConvBNReLU(stem_chs[2], stem_chs[2], kernel_size=3, stride=2),\n",
            "        )\n",
            "        input_channel = stem_chs[-1]\n",
            "        features = []\n",
            "        idx = 0\n",
            "        dpr = [x.item() for x in torch.linspace(0, path_dropout, sum(depths))]  # stochastic depth decay rule\n",
            "        for stage_id in range(len(depths)):\n",
            "            numrepeat = depths[stage_id]\n",
            "            output_channels = self.stage_out_channels[stage_id]\n",
            "            block_types = self.stage_block_types[stage_id]\n",
            "            for block_id in range(numrepeat):\n",
            "                if strides[stage_id] == 2 and block_id == 0:\n",
            "                    stride = 2\n",
            "                else:\n",
            "                    stride = 1\n",
            "                output_channel = output_channels[block_id]\n",
            "                block_type = block_types[block_id]\n",
            "                if block_type is ECB:\n",
            "                    layer = ECB(input_channel, output_channel, stride=stride, path_dropout=dpr[idx + block_id],\n",
            "                                drop=drop, head_dim=head_dim)\n",
            "                    features.append(layer)\n",
            "                elif block_type is LTB:\n",
            "                    layer = LTB(input_channel, output_channel, path_dropout=dpr[idx + block_id], stride=stride,\n",
            "                                sr_ratio=sr_ratios[stage_id], head_dim=head_dim, mix_block_ratio=mix_block_ratio,\n",
            "                                attn_drop=attn_drop, drop=drop)\n",
            "                    features.append(layer)\n",
            "                input_channel = output_channel\n",
            "            idx += numrepeat\n",
            "        self.features = nn.Sequential(*features)\n",
            "\n",
            "        self.norm = nn.BatchNorm2d(output_channel, eps=NORM_EPS)\n",
            "\n",
            "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
            "        self.proj_head = nn.Sequential(\n",
            "            nn.Linear(output_channel, num_classes),\n",
            "        )\n",
            "\n",
            "        self.stage_out_idx = [sum(depths[:idx + 1]) - 1 for idx in range(len(depths))]\n",
            "        print('initialize_weights...')\n",
            "        self._initialize_weights()\n",
            "\n",
            "    def merge_bn(self):\n",
            "        self.eval()\n",
            "        for idx, module in self.named_modules():\n",
            "            if isinstance(module, ECB) or isinstance(module, LTB):\n",
            "                module.merge_bn()\n",
            "\n",
            "    def _initialize_weights(self):\n",
            "        for n, m in self.named_modules():\n",
            "            if isinstance(m, (nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm, nn.BatchNorm1d)):\n",
            "                nn.init.constant_(m.weight, 1.0)\n",
            "                nn.init.constant_(m.bias, 0)\n",
            "            elif isinstance(m, nn.Linear):\n",
            "                trunc_normal_(m.weight, std=.02)\n",
            "                if hasattr(m, 'bias') and m.bias is not None:\n",
            "                    nn.init.constant_(m.bias, 0)\n",
            "            elif isinstance(m, nn.Conv2d):\n",
            "                trunc_normal_(m.weight, std=.02)\n",
            "                if hasattr(m, 'bias') and m.bias is not None:\n",
            "                    nn.init.constant_(m.bias, 0)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.stem(x)\n",
            "        for idx, layer in enumerate(self.features):\n",
            "            if self.use_checkpoint:\n",
            "                x = checkpoint.checkpoint(layer, x)\n",
            "            else:\n",
            "                x = layer(x)\n",
            "        x = self.norm(x)\n",
            "        x = self.avgpool(x)\n",
            "        x = torch.flatten(x, 1)\n",
            "        x = self.proj_head(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "@register_model\n",
            "def MedViT_small(pretrained=False, pretrained_cfg=None, **kwargs):\n",
            "    model = MedViT(stem_chs=[64, 32, 64], depths=[3, 4, 10, 3], path_dropout=0.1, **kwargs)\n",
            "    return model\n",
            "\n",
            "\n",
            "@register_model\n",
            "def MedViT_base(pretrained=False, pretrained_cfg=None, **kwargs):\n",
            "    model = MedViT(stem_chs=[64, 32, 64], depths=[3, 4, 20, 3], path_dropout=0.2, **kwargs)\n",
            "    return model\n",
            "\n",
            "\n",
            "@register_model\n",
            "def MedViT_large(pretrained=False, pretrained_cfg=None, **kwargs):\n",
            "    model = MedViT(stem_chs=[64, 32, 64], depths=[3, 4, 30, 3], path_dropout=0.2, **kwargs)\n",
            "    return model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tiny(num_classes=n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-ulnImfc67E",
        "outputId": "205f15db-ad0f-4c5b-90d2-ee3fa3bff303"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjTRIn77d1jS",
        "outputId": "7f227f2d-a524-4031-f5a9-625a88e590b5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=4, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model's final layer is already configured with the correct number of classes during instantiation, so this line is no longer needed."
      ],
      "metadata": {
        "id": "uPWfc-DYd1gu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")"
      ],
      "metadata": {
        "id": "7xl7x9bZd1d7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"/content/drive/MyDrive/CKDupdated.zip\"\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SZVLyvwTd1bO",
        "outputId": "ef55600a-fe83-4bfe-b34c-9cc2217a173e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CKDupdated.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "Z1cc5SJ3eeSd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "# The 'INFO' dictionary and 'data_flag' variable were not defined.\n",
        "# Based on the model's last layer configuration, n_classes should be 2.\n",
        "# If 'task' and 'n_channels' are needed, they should be defined explicitly.\n",
        "# info = INFO[data_flag]\n",
        "task = 'multi-class' # Defined as multi-class based on the dataset structure\n",
        "# n_channels = info['n_channels']\n",
        "n_classes = 4 # Inferred from the model's final linear layer output (out_features=2), but corrected to 4 based on the dataset classes"
      ],
      "metadata": {
        "id": "yzts6NXpeeO_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-3JtqkOneeMe",
        "outputId": "1d752db4-0d44-409e-9318-f90b8548f83e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DataClass' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-545943781.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataClass' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0649e70",
        "outputId": "eb7732c8-1dd5-4032-b827-c57176014c63"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = dataset # Use the already defined 'dataset' variable\n",
        "extract_path = '/content/CKDupdated'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f'Dataset extracted to: {extract_path}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to: /content/CKDupdated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9e8333d",
        "outputId": "fb2e453d-d0dc-4c58-bff3-68924c41ad43"
      },
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize to a fixed square size\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) # Normalize for 3 channels\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize to a fixed square size\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) # Normalize for 3 channels\n",
        "])\n",
        "\n",
        "# Define the path to the unzipped dataset where class folders are directly present\n",
        "data_dir = '/content/CKDupdated/CKDupdated'\n",
        "\n",
        "# Load the entire dataset using ImageFolder\n",
        "full_dataset = ImageFolder(root=data_dir, transform=train_transform)\n",
        "\n",
        "# Define the split ratio for training and testing\n",
        "train_size = int(0.8 * len(full_dataset)) # 80% for training\n",
        "test_size = len(full_dataset) - train_size # Remaining for testing\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "# For the test dataset, we might want to apply a different transform if AugMix is only for training\n",
        "# However, since random_split creates subsets, we need to handle transforms differently.\n",
        "# A common approach is to create two full datasets with different transforms and then split.\n",
        "# For simplicity and direct fix, we'll keep the same transform for now unless specified otherwise.\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "# print(f\"Classes: {full_dataset.classes}\") # Classes can be accessed from full_dataset"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 1600\n",
            "Number of test samples: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Check the contents of the extracted directory to confirm the correct path\n",
        "print(os.listdir('/content/CKDupdated/CKDupdated'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLn578rReeJ-",
        "outputId": "675e1f91-1774-48da-9732-37efe5adf93a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stone_up', 'Normal_up', 'cyst_up', 'tumor_up']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "# task is defined as 'multi-class'\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk9eDjSkeeHN",
        "outputId": "69bba635-dff8-4f04-b572-3fa9b1e1046b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:54<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:53<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:54<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:54<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:54<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:54<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:53<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:53<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:53<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:54<00:00,  2.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# evaluation\n",
        "\n",
        "# Define a simple Evaluator class\n",
        "class Evaluator:\n",
        "    def __init__(self, data_flag, split):\n",
        "        self.data_flag = data_flag\n",
        "        self.split = split\n",
        "\n",
        "    def evaluate(self, y_score, y_true):\n",
        "        # For multi-class, y_score will be probabilities, y_true will be class indices\n",
        "        # Calculate accuracy\n",
        "        y_pred = np.argmax(y_score, axis=1)\n",
        "        correct_predictions = np.sum(y_pred == y_true)\n",
        "        accuracy = correct_predictions / len(y_true)\n",
        "\n",
        "        # Calculate multi-class AUC using one-vs-rest strategy with macro averaging\n",
        "        # roc_auc_score requires y_true to be integers (class labels) and y_score to be probabilities.\n",
        "        # The 'multi_class' parameter is set to 'ovr' (one-vs-rest) and 'average' to 'macro').\n",
        "        # Explicitly pass 'labels' to handle cases where not all classes are present in y_true.\n",
        "        try:\n",
        "            auc = roc_auc_score(y_true, y_score, multi_class='ovr', average='macro', labels=np.arange(n_classes))\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: Could not compute AUC. {e}\")\n",
        "            auc = 0.0 # Fallback in case AUC cannot be computed (e.g., single class present in batch)\n",
        "\n",
        "        return auc, accuracy\n",
        "\n",
        "# Define data_flag - it was not defined previously\n",
        "data_flag = \"CKD_dataset\" # Example placeholder\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    all_y_true = []\n",
        "    all_y_score = []\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                # For multi-class, targets should be long (class indices)\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "\n",
        "            all_y_true.append(targets.cpu().numpy())\n",
        "            all_y_score.append(outputs.cpu().numpy())\n",
        "\n",
        "        y_true_np = np.concatenate(all_y_true, axis=0)\n",
        "        y_score_np = np.concatenate(all_y_score, axis=0)\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        auc, accuracy = evaluator.evaluate(y_score_np, y_true_np) # Pass y_true_np to evaluator\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, auc, accuracy))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3MmDkGQeeEu",
        "outputId": "119437dc-602a-496f-ca99-33cec2a072a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  auc: 1.000  acc:0.994\n",
            "test  auc: 0.998  acc:0.993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2XYOyvDeeCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}